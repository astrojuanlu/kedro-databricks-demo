{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f44b92b1-640b-4ee4-8dd8-2041f9438a8e",
     "showTitle": false,
     "title": ""
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# First Steps with Kedro on Databricks\n",
    "\n",
    "<img src=\"static/kedro-horizontal-color-on-light.png\" alt=\"Kedro\" width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe4651d9-a323-4e1d-8ac2-65ade4cde293",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "First, let's install `uv` (a super fast `pip` replacement written in Rust) and our dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4085138c-b95c-479a-b64d-f9787958f8a6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install uv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10f203d6-6056-4a26-8ca3-62420c88e9c4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!uv pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b58da34-93f3-47ce-b8ef-d614475fa5f9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b4e024a-4578-4fd3-b71b-4f90c3e3c8b1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## An example with the NYC Taxi dataset\n",
    "\n",
    "The Unity Catalog contains an example dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a95397bb-0381-42ca-8755-a295bd0c78e0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>tpep_pickup_datetime</th><th>tpep_dropoff_datetime</th><th>trip_distance</th><th>fare_amount</th><th>pickup_zip</th><th>dropoff_zip</th></tr></thead><tbody><tr><td>2016-02-14T16:52:13Z</td><td>2016-02-14T17:16:04Z</td><td>4.94</td><td>19.0</td><td>10282</td><td>10171</td></tr><tr><td>2016-02-04T18:44:19Z</td><td>2016-02-04T18:46:00Z</td><td>0.28</td><td>3.5</td><td>10110</td><td>10110</td></tr><tr><td>2016-02-17T17:13:57Z</td><td>2016-02-17T17:17:55Z</td><td>0.7</td><td>5.0</td><td>10103</td><td>10023</td></tr><tr><td>2016-02-18T10:36:07Z</td><td>2016-02-18T10:41:45Z</td><td>0.8</td><td>6.0</td><td>10022</td><td>10017</td></tr><tr><td>2016-02-22T14:14:41Z</td><td>2016-02-22T14:31:52Z</td><td>4.51</td><td>17.0</td><td>10110</td><td>10282</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "2016-02-14T16:52:13Z",
         "2016-02-14T17:16:04Z",
         4.94,
         19,
         10282,
         10171
        ],
        [
         "2016-02-04T18:44:19Z",
         "2016-02-04T18:46:00Z",
         0.28,
         3.5,
         10110,
         10110
        ],
        [
         "2016-02-17T17:13:57Z",
         "2016-02-17T17:17:55Z",
         0.7,
         5,
         10103,
         10023
        ],
        [
         "2016-02-18T10:36:07Z",
         "2016-02-18T10:41:45Z",
         0.8,
         6,
         10022,
         10017
        ],
        [
         "2016-02-22T14:14:41Z",
         "2016-02-22T14:31:52Z",
         4.51,
         17,
         10110,
         10282
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": "_sqldf",
        "executionCount": 4
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "tpep_pickup_datetime",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "tpep_dropoff_datetime",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "trip_distance",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "fare_amount",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "pickup_zip",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "dropoff_zip",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "USE CATALOG samples;\n",
    "USE SCHEMA nyctaxi;\n",
    "SELECT * FROM trips LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40a586fc-ce16-4c59-9460-e922ecaf8354",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## The `DataCatalog`\n",
    "\n",
    "Kedro’s [Data Catalog](https://docs.kedro.org/en/latest/data/) is a registry of all data sources available for use by the project. It offers a separate place to declare details of the datasets your projects use. Kedro provides built-in datasets for different file types and file systems so you don’t have to write any of the logic for reading or writing data.\n",
    "\n",
    "Kedro offers a range of datasets, including CSV, Excel, Parquet, Feather, HDF5, JSON, Pickle, SQL Tables, SQL Queries, Spark DataFrames, and more. They are supported with the APIs of pandas, spark, networkx, matplotlib, yaml, and beyond. It relies on fsspec to read and save data from a variety of data stores including local file systems, network file systems, cloud object stores, and Hadoop. You can pass arguments in to load and save operations, and use versioning and credentials for data access.\n",
    "\n",
    "To start using the Data Catalog, create an instance of the `DataCatalog` class with a dictionary configuration as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6a1cc5d-60c7-411f-84c5-01047f5e978c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd304399-077e-4fe8-88c1-70983bbc57ce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:py4j.clientserver:Received command c on object id p0\n"
     ]
    }
   ],
   "source": [
    "from kedro.io import DataCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d61c1cf4-f385-4247-83c2-55e13a5d2a48",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:py4j.clientserver:Received command c on object id p0\n"
     ]
    }
   ],
   "source": [
    "catalog = DataCatalog.from_config(\n",
    "    {\n",
    "        \"nyctaxi_trips\": {\n",
    "            \"type\": \"databricks.ManagedTableDataset\",\n",
    "            \"catalog\": \"samples\",\n",
    "            \"database\": \"nyctaxi\",\n",
    "            \"table\": \"trips\",\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "241709ef-8951-491e-9365-a561126b3095",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Each entry in the dictionary represents a **dataset**, and each dataset has a **type** as well as some extra properties. Datasets are Python classes that take care of all the I/O needs in Kedro. In this case, we're using `kedro_datasets.ibis.TableDataset`, you can read [its full documentation](https://docs.kedro.org/projects/kedro-datasets/en/kedro-datasets-3.0.1/api/kedro_datasets.ibis.TableDataset.html) online.\n",
    "\n",
    "After the catalog is created, `catalog.list()` will yield a list of the available dataset names, which you can load using the `catalog.load(<dataset_name>)` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4571dc9f-1e89-4fb0-9488-48c730526612",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:py4j.clientserver:Received command c on object id p0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['nyctaxi_trips']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7dce890f-60be-4c01-bee7-b4268f562b9e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:kedro.io.data_catalog:Loading data from [dark_orange]nyctaxi_trips[/dark_orange] (ManagedTableDataset)...\n"
     ]
    }
   ],
   "source": [
    "nyctaxi_trips = catalog.load(\"nyctaxi_trips\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c83a22ca-0de8-45cd-b62b-b75375ef1a83",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Notice that the resulting object is the exact same Ibis table we were using in the previous tutorial!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a5b9561-c64f-4419-91a5-c731d78667a8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:py4j.clientserver:Received command c on object id p0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nyctaxi_trips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a501aff-2227-4f19-b914-2d1272bf95aa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:py4j.clientserver:Received command c on object id p0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+-------------+-----------+----------+-----------+\n",
      "|tpep_pickup_datetime|tpep_dropoff_datetime|trip_distance|fare_amount|pickup_zip|dropoff_zip|\n",
      "+--------------------+---------------------+-------------+-----------+----------+-----------+\n",
      "| 2016-02-14 16:52:13|  2016-02-14 17:16:04|         4.94|       19.0|     10282|      10171|\n",
      "| 2016-02-04 18:44:19|  2016-02-04 18:46:00|         0.28|        3.5|     10110|      10110|\n",
      "| 2016-02-17 17:13:57|  2016-02-17 17:17:55|          0.7|        5.0|     10103|      10023|\n",
      "| 2016-02-18 10:36:07|  2016-02-18 10:41:45|          0.8|        6.0|     10022|      10017|\n",
      "| 2016-02-22 14:14:41|  2016-02-22 14:31:52|         4.51|       17.0|     10110|      10282|\n",
      "+--------------------+---------------------+-------------+-----------+----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nyctaxi_trips.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd0a517e-50cc-42f4-8278-8a8c31f8d2da",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## The `OmegaConfigLoader`\n",
    "\n",
    "Instead of creating the Data Catalog by hand like this, Kedro usually stores configuration in YAML files. To load them, Kedro offers a [configuration loader](https://docs.kedro.org/en/latest/configuration/configuration_basics.html) based on the [Omegaconf](https://omegaconf.readthedocs.io/) library called the `OmegaConfigLoader`. This adds several interesting features, such as\n",
    "\n",
    "- Consolidating different configuration files into one\n",
    "- Substitution, templating\n",
    "- [Resolvers](https://omegaconf.readthedocs.io/en/2.3_branch/custom_resolvers.html)\n",
    "- And [much more](https://docs.kedro.org/en/latest/configuration/advanced_configuration.html)\n",
    "\n",
    "To start using it, first dump the catalog configuration to a `catalog.yml` file, and then use `OmegaConfigLoader` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "771df6d0-a259-44c1-ab0a-6f8aaa0cb631",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:py4j.clientserver:Received command c on object id p0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting catalog.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile catalog.yml\n",
    "nyctaxi_trips:\n",
    "  type: databricks.ManagedTableDataset\n",
    "  catalog: samples\n",
    "  database: nyctaxi\n",
    "  table: trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcb2acde-31de-4886-ac60-3bb5f0546fb7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:py4j.clientserver:Received command c on object id p0\n"
     ]
    }
   ],
   "source": [
    "from kedro.config import OmegaConfigLoader\n",
    "\n",
    "config_loader = OmegaConfigLoader(\n",
    "    conf_source=\".\",  # Directory where configuration files are located\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "433dca34-8072-47bb-956b-1b12353ddb33",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:py4j.clientserver:Received command c on object id p0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'nyctaxi_trips': {'type': 'databricks.ManagedTableDataset',\n",
       "  'catalog': 'samples',\n",
       "  'database': 'nyctaxi',\n",
       "  'table': 'trips'}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog_config = config_loader.get(\"catalog\")\n",
    "catalog_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a8d3fca-9ecc-4aa5-b678-6da1e978970b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "As you can see, `config_loader.get(\"catalog\")` gets you the same dictionary we crafted by hand earlier.\n",
    "\n",
    "However, hardcoding the database path like that seems like an invitation to trouble. Let's declare a variable `_root` inside the YAML file using Omegaconf syntax and load the catalog config again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfeeadc3-a140-4237-a8a0-78cdb821892d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:py4j.clientserver:Received command c on object id p0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting catalog.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile catalog.yml\n",
    "_type: databricks.ManagedTableDataset\n",
    "\n",
    "nyctaxi_trips:\n",
    "  type: ${_type}\n",
    "  catalog: samples\n",
    "  database: nyctaxi\n",
    "  table: trips\n",
    "\n",
    "# Adding an extra dataset for demonstration purposes\n",
    "tpch_orders:\n",
    "  type: ${_type}\n",
    "  catalog: samples\n",
    "  database: tpch\n",
    "  table: orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4a232f5-26a1-4f1f-aba2-57d93a06b815",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:py4j.clientserver:Received command c on object id p0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'nyctaxi_trips': {'type': 'databricks.ManagedTableDataset',\n",
       "  'catalog': 'samples',\n",
       "  'database': 'nyctaxi',\n",
       "  'table': 'trips'},\n",
       " 'tpch_orders': {'type': 'databricks.ManagedTableDataset',\n",
       "  'catalog': 'samples',\n",
       "  'database': 'tpch',\n",
       "  'table': 'orders'}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog_config = config_loader.get(\"catalog\")\n",
    "catalog_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c43fa6bf-5d27-4083-b673-5d29ea5a8df9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog = DataCatalog.from_config(catalog_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ca78e97-ca59-479d-96a4-7377cb090a4a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:py4j.clientserver:Received command c on object id p0\n",
      "INFO:kedro.io.data_catalog:Loading data from [dark_orange]nyctaxi_trips[/dark_orange] (ManagedTableDataset)...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, trip_distance: double, fare_amount: double, pickup_zip: int, dropoff_zip: int]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog.load(\"nyctaxi_trips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a93d93e7-a163-484c-ba98-1b4dc9bf101c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:py4j.clientserver:Received command c on object id p0\n",
      "INFO:kedro.io.data_catalog:Loading data from [dark_orange]tpch_orders[/dark_orange] (ManagedTableDataset)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------------+------------+-----------+---------------+---------------+--------------+--------------------+\n",
      "|o_orderkey|o_custkey|o_orderstatus|o_totalprice|o_orderdate|o_orderpriority|        o_clerk|o_shippriority|           o_comment|\n",
      "+----------+---------+-------------+------------+-----------+---------------+---------------+--------------+--------------------+\n",
      "|  13710944|   227285|            O|   162169.66| 1995-10-11|       1-URGENT|Clerk#000000432|             0|accounts. ruthles...|\n",
      "|  13710945|   225010|            O|   252273.67| 1997-09-29|          5-LOW|Clerk#000002337|             0|ironic platelets ...|\n",
      "|  13710946|   238820|            O|   179947.16| 1997-10-31|         2-HIGH|Clerk#000004135|             0|ole requests. reg...|\n",
      "|  13710947|   581233|            O|    33843.49| 1995-05-25|         2-HIGH|Clerk#000000138|             0|arefully final pl...|\n",
      "|  13710948|    10033|            O|    42500.65| 1995-09-04|4-NOT SPECIFIED|Clerk#000003398|             0|regular requests ...|\n",
      "+----------+---------+-------------+------------+-----------+---------------+---------------+--------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tpch_orders = catalog.load(\"tpch_orders\")\n",
    "tpch_orders.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f1786d5-0d36-4e8f-8d34-7ee14d3fd747",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Nodes and pipelines\n",
    "\n",
    "Now comes the interesting part. Kedro structures the computation on Directed Acyclic Graphs (DAGs), which are created by instantiating `Pipeline` objects with a list of `Node`s. By linking the inputs and outpus of each node, Kedro is then able to perform a topological sort and produce a graph.\n",
    "\n",
    "Let's start creating a trivial pipeline with 1 node. That 1 node will be a preprocessing function that will manipulate the `dep_time`, `arr_delay`, and `air_time` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "daa6af0f-a4b7-4a0c-929c-b8150bad90a1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:py4j.clientserver:Received command c on object id p0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "def preprocess_nyc_taxi_data(df: DataFrame) -> DataFrame:\n",
    "    # Remove trips with no distance or fare amount\n",
    "    cleaned_df = df.filter((col(\"trip_distance\") > 0) & (col(\"fare_amount\") > 0))\n",
    "\n",
    "    # Add a new column for trip duration in minutes\n",
    "    cleaned_df = cleaned_df.withColumn(\n",
    "        \"trip_duration_minutes\",\n",
    "        (col(\"tpep_dropoff_datetime\").cast(\"long\") - col(\"tpep_pickup_datetime\").cast(\"long\")) / 60\n",
    "    )\n",
    "\n",
    "    # Filter out trips with unrealistic duration (> 0 and <= 600 minutes)\n",
    "    cleaned_df = cleaned_df.filter(\n",
    "        (col(\"trip_duration_minutes\") > 0) & (col(\"trip_duration_minutes\") <= 600)\n",
    "    )\n",
    "\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66fed5ac-9835-4305-ae2b-ebb634b9027a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:py4j.clientserver:Received command c on object id p0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+-------------+-----------+----------+-----------+\n",
      "|tpep_pickup_datetime|tpep_dropoff_datetime|trip_distance|fare_amount|pickup_zip|dropoff_zip|\n",
      "+--------------------+---------------------+-------------+-----------+----------+-----------+\n",
      "| 2016-02-14 16:52:13|  2016-02-14 17:16:04|         4.94|       19.0|     10282|      10171|\n",
      "| 2016-02-04 18:44:19|  2016-02-04 18:46:00|         0.28|        3.5|     10110|      10110|\n",
      "| 2016-02-17 17:13:57|  2016-02-17 17:17:55|          0.7|        5.0|     10103|      10023|\n",
      "| 2016-02-18 10:36:07|  2016-02-18 10:41:45|          0.8|        6.0|     10022|      10017|\n",
      "| 2016-02-22 14:14:41|  2016-02-22 14:31:52|         4.51|       17.0|     10110|      10282|\n",
      "+--------------------+---------------------+-------------+-----------+----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nyctaxi_trips.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fab6879-716b-42dd-bc5a-d0bfed9ff5c5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:py4j.clientserver:Received command c on object id p0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+-------------+-----------+----------+-----------+---------------------+\n",
      "|tpep_pickup_datetime|tpep_dropoff_datetime|trip_distance|fare_amount|pickup_zip|dropoff_zip|trip_duration_minutes|\n",
      "+--------------------+---------------------+-------------+-----------+----------+-----------+---------------------+\n",
      "| 2016-02-16 22:40:45|  2016-02-16 22:59:25|         5.35|       18.5|     10003|      11238|   18.666666666666668|\n",
      "| 2016-02-05 16:06:44|  2016-02-05 16:26:03|          6.5|       21.5|     10282|      10001|   19.316666666666666|\n",
      "| 2016-02-08 07:39:25|  2016-02-08 07:44:14|          0.9|        5.5|     10119|      10003|    4.816666666666666|\n",
      "| 2016-02-29 22:25:33|  2016-02-29 22:38:09|          3.5|       13.5|     10001|      11222|                 12.6|\n",
      "| 2016-02-03 17:21:02|  2016-02-03 17:23:24|          0.3|        3.5|     10028|      10028|   2.3666666666666667|\n",
      "+--------------------+---------------------+-------------+-----------+----------+-----------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocess_nyc_taxi_data(nyctaxi_trips).show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2b3fd81-9071-4ba6-b9ff-c83960ec534a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Notice that this is a plain Python function, receiving an Ibis table and returning another Ibis table.\n",
    "\n",
    "Now, let's wrap it using the `node` convenience function from Kedro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98b82f40-e81f-4f87-8baf-119cd7e754fc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:py4j.clientserver:Received command c on object id p0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Node(preprocess_nyc_taxi_data, 'nyctaxi_trips', 'preprocessed_nyctaxi_trips', None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kedro.pipeline import node\n",
    "\n",
    "n0 = node(\n",
    "    func=preprocess_nyc_taxi_data,\n",
    "    inputs=\"nyctaxi_trips\",\n",
    "    outputs=\"preprocessed_nyctaxi_trips\"\n",
    ")\n",
    "n0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cbb449b-67a5-4ff6-bbe7-d4abf3ad44a5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Conceptually, a `Node` is a wrapper around a Python function that defines a single step in a pipeline. It has inputs and outputs, which are the names of the Data Catalog datasets that the function will receive and return, respectively. Therefore, you could execute it as follows:\n",
    "\n",
    "```python\n",
    "n0.func(\n",
    "    *[catalog.load(input_dataset) for input_dataset in n0.inputs],\n",
    ")\n",
    "```\n",
    "\n",
    "Let's not do that though; Kedro will take care of it.\n",
    "\n",
    "The next step is to assemble the pipeline. In this case, it will only have 1 node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cc02764-dd8e-497f-b28b-4605808fc69e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:py4j.clientserver:Received command c on object id p0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline([\n",
       "Node(preprocess_nyc_taxi_data, 'nyctaxi_trips', 'preprocessed_nyctaxi_trips', None)\n",
       "])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kedro.pipeline import pipeline\n",
    "\n",
    "pipe = pipeline([n0])\n",
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b67d597-593f-4732-b615-7994ca568d69",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "And finally, you can now execute the pipeline. For the purposes of this tutorial, you can use Kedro's `SequentialRunner` directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e607960-7781-4648-8300-3956539e6712",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:py4j.clientserver:Received command c on object id p0\n"
     ]
    }
   ],
   "source": [
    "# Workaround: Restore logging handlers, see https://github.com/kedro-org/kedro/issues/3985\n",
    "\n",
    "import logging\n",
    "\n",
    "_old_handlers = logging.getLogger().handlers.copy()\n",
    "\n",
    "import kedro.runner\n",
    "\n",
    "logging.getLogger().handlers = _old_handlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1f9648e-f921-4971-9109-c795f32a4f36",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:kedro.runner.sequential_runner:Using synchronous mode for loading and saving data. Use the --async flag for potential performance gains. https://docs.kedro.org/en/stable/nodes_and_pipelines/run_a_pipeline.html#load-and-save-asynchronously\n",
      "INFO:kedro.io.data_catalog:Loading data from [dark_orange]nyctaxi_trips[/dark_orange] (ManagedTableDataset)...\n",
      "INFO:kedro.pipeline.node:Running node: preprocess_nyc_taxi_data([nyctaxi_trips]) -> [preprocessed_nyctaxi_trips]\n",
      "INFO:kedro.io.data_catalog:Saving data to [dark_orange]preprocessed_nyctaxi_trips[/dark_orange] (MemoryDataset)...\n",
      "INFO:kedro.runner.sequential_runner:Completed 1 out of 1 tasks\n",
      "INFO:kedro.runner.sequential_runner:Pipeline execution completed successfully.\n",
      "INFO:kedro.io.data_catalog:Loading data from [dark_orange]preprocessed_nyctaxi_trips[/dark_orange] (MemoryDataset)...\n"
     ]
    }
   ],
   "source": [
    "from kedro.runner import SequentialRunner\n",
    "\n",
    "outputs = SequentialRunner().run(pipe, catalog=catalog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a75082ec-44e5-4690-bec8-cb66159619e8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The output of the `.run(...)` method will be \"Any node outputs that cannot be processed by the `DataCatalog`\". Since `preprocessed_nyctaxi_trips` is not declared in the Data Catalog, it's right there in the dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72581dd5-09d9-43d6-bdb4-8726d3aa0955",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:py4j.clientserver:Received command c on object id p0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['preprocessed_nyctaxi_trips'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5986e58-b2e9-4cd2-91ba-2045c955ca93",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:py4j.clientserver:Received command c on object id p0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+-------------+-----------+----------+-----------+---------------------+\n",
      "|tpep_pickup_datetime|tpep_dropoff_datetime|trip_distance|fare_amount|pickup_zip|dropoff_zip|trip_duration_minutes|\n",
      "+--------------------+---------------------+-------------+-----------+----------+-----------+---------------------+\n",
      "| 2016-02-16 22:40:45|  2016-02-16 22:59:25|         5.35|       18.5|     10003|      11238|   18.666666666666668|\n",
      "| 2016-02-05 16:06:44|  2016-02-05 16:26:03|          6.5|       21.5|     10282|      10001|   19.316666666666666|\n",
      "| 2016-02-08 07:39:25|  2016-02-08 07:44:14|          0.9|        5.5|     10119|      10003|    4.816666666666666|\n",
      "| 2016-02-29 22:25:33|  2016-02-29 22:38:09|          3.5|       13.5|     10001|      11222|                 12.6|\n",
      "| 2016-02-03 17:21:02|  2016-02-03 17:23:24|          0.3|        3.5|     10028|      10028|   2.3666666666666667|\n",
      "+--------------------+---------------------+-------------+-----------+----------+-----------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs[\"preprocessed_nyctaxi_trips\"].show(n=5)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4172678518454607,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "First Steps with Kedro on Databricks",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
